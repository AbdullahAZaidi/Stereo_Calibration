{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stereo_cal",
      "provenance": [],
      "mount_file_id": "1t8o-tgbBeGB3lXs55ra8xgxQ3PNoTliL",
      "authorship_tag": "ABX9TyMw7o4qHvMxsacVzIH3FG8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdullahAZaidi/Stereo_Calibration/blob/main/stereo_alignment_factory_primax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhoeSFm5THaj",
        "outputId": "d6e5def4-2a69-40d6-f784-d43440ac2038"
      },
      "source": [
        "from io import StringIO\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from typing import NamedTuple, Any\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import h5py\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "df = pd.read_excel('/content/gdrive/Shareddrives/External_Primax/Sample_Calibration_Data_Abdullah/P10_Intrinsic_calibration.xlsx')\n",
        "\n",
        "translation_x_min = 390\n",
        "translation_x_max = 410\n",
        "\n",
        "translation_y_min = -10\n",
        "translation_y_max = 10\n",
        "\n",
        "translation_z_min = -10\n",
        "translation_z_max = 10\n",
        "\n",
        "rotation_min = -0.0001\n",
        "rotation_max = 0.0001\n",
        "\n",
        "def load_camera_matrix(Camera):\n",
        "  Fx = df[Camera].values[0]\n",
        "  Fy = df[Camera].values[1]\n",
        "  Cx = df[Camera].values[2]\n",
        "  Cy = df[Camera].values[3]\n",
        "  \n",
        "  return np.array([[ Fx,  0.,  Cx ],\n",
        "                  [ 0.,  Fy,  Cy ],\n",
        "                  [ 0.,  0.,  1 ]])\n",
        "\n",
        "\n",
        "def load_dist_coeff(Camera):\n",
        "  K1 = df[Camera].values[4]\n",
        "  K2 = df[Camera].values[5]\n",
        "  P1 = df[Camera].values[6]\n",
        "  P2 = df[Camera].values[7]\n",
        "  K3 = df[Camera].values[8]\n",
        "\n",
        "  return np.array ([K1, K2, P1, P2, K3])\n",
        "\n",
        "\n",
        "def translation_x_highlight(val):\n",
        "    color = 'green' if translation_x_min <val < translation_x_max else 'red'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "def translation_y_highlight(val):\n",
        "    color = 'green' if translation_y_min <val < translation_y_max else 'red'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "def translation_z_highlight(val):\n",
        "    color = 'green' if translation_z_min <val < translation_z_max else 'red'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "def rotation_highlight(val):\n",
        "    color = 'green' if rotation_min <val < rotation_max else 'red'\n",
        "    return 'color: %s' % color\n",
        "\n",
        "\n",
        "def write_trans_rot_errors(sheet, output):\n",
        "\n",
        "  vals = {'translation_x': [output[0]],\n",
        "          'translation_y': [output[1]],\n",
        "          'translation_z': [output[2]],\n",
        "          'rotation_x': [output[3]],\n",
        "          'rotation_y': [output[4]],\n",
        "          'rotation_z': [output[5]],\n",
        "        }\n",
        "\n",
        "  df = pd.DataFrame(vals, columns = ['pairs','translation_x', 'translation_y', 'translation_z','rotation_x','rotation_y','rotation_z'])\n",
        "  df.style.\\\n",
        "    applymap(translation_x_highlight,subset=['translation_x']).\\\n",
        "    applymap(translation_y_highlight,subset=['translation_y']).\\\n",
        "    applymap(translation_z_highlight,subset=['translation_z']).\\\n",
        "    applymap(rotation_highlight,subset=['rotation_x','rotation_y','rotation_z']).\\\n",
        "    to_excel(sheet, index = False, engine='openpyxl')\n",
        "  # df.to_excel(sheet, index = False, header=True)\n",
        "                  \n",
        "\n",
        "def _find_checkerboard_corners(tgt_size, imfile_path: Path) -> Any:\n",
        "    print(f'Loading {imfile_path} ...', file=sys.stderr)\n",
        "    assert imfile_path.is_file(), f\"{imfile_path} is not a valid file\"\n",
        "    im = cv2.imread(str(imfile_path))\n",
        "    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "#     plt.imshow(im)\n",
        "\n",
        "    print('  finding chessboard corners ...', file=sys.stderr)\n",
        "    pattern_was_found, pixel_corners = cv2.findChessboardCorners(gray_im, tgt_size, flags=cv2.CALIB_CB_FAST_CHECK)\n",
        "    assert pattern_was_found, f\"No corners detected!\"\n",
        "#     cv2.cornerSubPix(gray_im, pixel_corners, (11, 11), (-1, 1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
        "\n",
        "    if (pixel_corners[0] > pixel_corners[-1]).all():\n",
        "        print(f'Flipping reversed checkboard detections for {imfile_path}', file=sys.stderr)\n",
        "        pixel_corners = pixel_corners[::-1]  # Corners must be top-bottom\n",
        "\n",
        "    print('  writing corner detection visualization ...', file=sys.stderr)\n",
        "    cv2.drawChessboardCorners(im, tgt_size, pixel_corners, pattern_was_found)\n",
        "    cv2.imwrite(f\"plots/{imfile_path.name}\", im)\n",
        "\n",
        "    return pixel_corners, gray_im.shape[::-1]\n",
        "\n",
        "def _find_checkerboard_corners2(tgt_size, imfile_path: Path) -> Any:\n",
        "    print(f'Loading {imfile_path} ...', file=sys.stderr)\n",
        "    assert imfile_path.is_file(), f\"{imfile_path} is not a valid file\"\n",
        "    im = cv2.imread(str(imfile_path))\n",
        "    im = im[0:im.shape[0]*5//9, 0:im.shape[1]]\n",
        "    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    plt.imshow(im)\n",
        "\n",
        "    print('  finding chessboard corners ...', file=sys.stderr)\n",
        "    pattern_was_found, pixel_corners = cv2.findChessboardCorners(gray_im, tgt_size, flags=cv2.CALIB_CB_FAST_CHECK)\n",
        "    assert pattern_was_found, f\"No corners detected!\"\n",
        "    cv2.cornerSubPix(gray_im, pixel_corners, (11, 11), (-1, 1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
        "\n",
        "    if (pixel_corners[0] > pixel_corners[-1]).all():\n",
        "        print(f'Flipping reversed checkboard detections for {imfile_path}', file=sys.stderr)\n",
        "        pixel_corners = pixel_corners[::-1]  # Corners must be top-bottom\n",
        "\n",
        "    print('  writing corner detection visualization ...', file=sys.stderr)\n",
        "    cv2.drawChessboardCorners(im, tgt_size, pixel_corners, pattern_was_found)\n",
        "    cv2.imwrite(f\"plots/{imfile_path.name}\", im)\n",
        "\n",
        "    return pixel_corners, gray_im.shape[::-1]\n",
        "\n",
        "\n",
        "def _load_correspondences_impl(tgt_size, img_file_paths, patch_size: float=25):\n",
        "    known_target_points = np.zeros((tgt_size[0] * tgt_size[1], 3), np.float32)\n",
        "    known_target_points[:,:2] = np.mgrid[0:tgt_size[0], 0:tgt_size[1]].T.reshape(-1,2) * patch_size\n",
        "\n",
        "    correspondences = {}\n",
        "    for file_path in img_file_paths:\n",
        "        pixel_corners, im_dimensions = _find_checkerboard_corners(tgt_size, file_path)\n",
        "        correspondences[file_path] = (known_target_points, pixel_corners, im_dimensions)\n",
        "    return correspondences\n",
        "\n",
        "def _load_correspondences_impl2(tgt_size, img_file_paths, patch_size: float=10):\n",
        "    known_target_points = np.zeros((tgt_size[0] * tgt_size[1], 3), np.float32)\n",
        "    known_target_points[:,:2] = np.mgrid[0:tgt_size[0], 0:tgt_size[1]].T.reshape(-1,2) * patch_size\n",
        "\n",
        "    correspondences = {}\n",
        "    for file_path in img_file_paths:\n",
        "        pixel_corners, im_dimensions = _find_checkerboard_corners(tgt_size, file_path)\n",
        "        correspondences[file_path] = (known_target_points, pixel_corners, im_dimensions)\n",
        "    return correspondences\n",
        "\n",
        "def load_correspondences_checkerboard(img_file_paths):\n",
        "    return _load_correspondences_impl((19, 13), img_file_paths)\n",
        "\n",
        "\n",
        "def load_correspondences_cross_chart(img_file_paths):\n",
        "    return _load_correspondences_impl2((14, 7), img_file_paths)\n",
        "\n",
        "\n",
        "def angle_axis_to_matrix(angle_axis: np.ndarray) -> np.ndarray:\n",
        "    \"\"\" Convert a rotation from an angle-axis representation to its\n",
        "    matrix representation.\n",
        "\n",
        "    Params\n",
        "    ------\n",
        "    `angle_axis`: numpy.ndarray with shape (3,)\n",
        "        This vector represents a rotation about an axis. Its magnitude\n",
        "        represents the angle of rotation, in radians, and its (unit-)\n",
        "        direction represents the axis of rotation. Hence a rotation of\n",
        "        π/4 about the z-axis would be represented as:\n",
        "        `np.array([0, 0, np.pi/4])`.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A unitary, orthonormal, 4x4 transformation matrix that represents the\n",
        "    same rotation as `angle_axis`.\n",
        "    \"\"\"\n",
        "    magnitude = np.linalg.norm(angle_axis)\n",
        "    angle, x, y, z = magnitude, *(angle_axis / magnitude)\n",
        "    K = np.array([ 0, -z,  y,\n",
        "                   z,  0, -x,\n",
        "                  -y,  x,  0 ]).reshape(3, 3)\n",
        "    # Compute exponential map (exp(K)) using Rodriguez's formula\n",
        "    R = np.eye(3) + (np.sin(angle) * K) + ((1 - np.cos(angle)) * (K @ K))\n",
        "\n",
        "    matrix_4x4 = np.eye(4)\n",
        "    matrix_4x4[:3, :3] = R\n",
        "    return matrix_4x4\n",
        "\n",
        "\n",
        "def translation_matrix(x: float, y: float, z: float):\n",
        "    \"\"\" Return a 4x4 matrix representating the (x, y, z) translation\n",
        "    \"\"\"\n",
        "    return np.array([[ 1.,  0.,  0.,  x  ],\n",
        "                     [ 0.,  1.,  0.,  y  ],\n",
        "                     [ 0.,  0.,  1.,  z  ],\n",
        "                     [ 0.,  0.,  0.,  1. ]])\n",
        "\n",
        "\n",
        "def rtvec_to_matrix(rvec, tvec) -> np.ndarray:\n",
        "    return translation_matrix(*tvec) @ angle_axis_to_matrix(rvec)\n",
        "\n",
        "\n",
        "def matrix_to_xyzrph(M: np.ndarray):\n",
        "    tx = M[0, 3]\n",
        "    ty = M[1, 3]\n",
        "    tz = M[2, 3]\n",
        "    rx = np.arctan2(M[2, 1],  M[2, 2])\n",
        "    ry = np.arctan2(-M[2, 0],  np.sqrt(M[0, 0]*M[0, 0] + M[1, 0]*M[1, 0]))\n",
        "    rz = np.arctan2(M[1, 0],  M[0, 0])\n",
        "    return tx, ty, tz, rx, ry, rz\n",
        "\n",
        "class CameraCalibrationResult(NamedTuple):\n",
        "    rms_reprojection_err: Any\n",
        "    cam_mat: Any\n",
        "    dist_coeffs: Any\n",
        "    cam_from_target_poses: Any\n",
        "\n",
        "\n",
        "def calibrate_camera(correspondences):\n",
        "    obj_points = [ o for o, _i, _s in correspondences.values() ]\n",
        "    img_points = [ i for _o, i, _s in correspondences.values() ]\n",
        "    im_shapes = [ s for _o, _i, s in correspondences.values() ]\n",
        "    assert all( im_shapes[0] == s for s in im_shapes )\n",
        "    rmse, cam_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, im_shapes[0], None, None)\n",
        "    cam_from_target_poses = [ rtvec_to_matrix(r.squeeze(), t.squeeze()) for r, t in zip(rvecs, tvecs) ]\n",
        "    return CameraCalibrationResult(rmse, cam_matrix, dist_coeffs, cam_from_target_poses)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \n",
        "    # loading camera matrix\n",
        "    left_cam_mat = load_camera_matrix('Camera 1')\n",
        "    right_cam_mat = load_camera_matrix('Camera 2')\n",
        "\n",
        "    #load distortion coefficients\n",
        "    left_dist_coeff = load_dist_coeff('Camera 1')\n",
        "    right_dist_coeff = load_dist_coeff('Camera 2')\n",
        "\n",
        "    lobj_points, limg_points, _ = list(load_correspondences_cross_chart([ Path('/content/gdrive/Shareddrives/External_Primax/Sample_Calibration_Data_Abdullah/L_PAIR10_CROSS0007.raw.bmp') ]).values())[0]\n",
        "    robj_points, rimg_points, _ = list(load_correspondences_cross_chart([ Path('/content/gdrive/Shareddrives/External_Primax/Sample_Calibration_Data_Abdullah/R_PAIR10_CROSS0007.raw.bmp') ]).values())[0]\n",
        "\n",
        "    _, r, t = cv2.solvePnP(lobj_points, limg_points, left_cam_mat, left_dist_coeff)\n",
        "    leftcam_from_chart = rtvec_to_matrix(r.squeeze(), t.squeeze())\n",
        "    \n",
        "    _, r, t = cv2.solvePnP(robj_points, rimg_points, right_cam_mat, right_dist_coeff)\n",
        "    rightcam_from_chart = rtvec_to_matrix(r.squeeze(), t.squeeze())\n",
        "\n",
        "    # print('Relative camera positions: ',\n",
        "    #       matrix_to_xyzrph(leftcam_from_chart @ np.linalg.inv(rightcam_from_chart)), file=sys.stderr)\n",
        "    \n",
        "    z = matrix_to_xyzrph(leftcam_from_chart @ np.linalg.inv(rightcam_from_chart))\n",
        "    write_trans_rot_errors('/content/gdrive/Shareddrives/External_Primax/Sample_Calibration_Data_Abdullah/Alignment_Data.xlsx', z)\n",
        "    # evaluate_pairs ('/content/gdrive/Shareddrives/External_Primax/Sample_Calibration_Data_Abdullah/Alignment_Data.xlsx')\n",
        "    print(z)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading /content/gdrive/Shareddrives/External_Primax/Sample_Calibration_Data_Abdullah/L_PAIR10_CROSS0007.raw.bmp ...\n",
            "  finding chessboard corners ...\n",
            "  writing corner detection visualization ...\n",
            "Loading /content/gdrive/Shareddrives/External_Primax/Sample_Calibration_Data_Abdullah/R_PAIR10_CROSS0007.raw.bmp ...\n",
            "  finding chessboard corners ...\n",
            "  writing corner detection visualization ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(396.4130928384445, -16.385892210189652, -2.370335944115368, -0.02437012765141098, -0.004078800261767037, -0.008336011462681512)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}